{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddc7489c-4c29-46fb-b27f-983d561e2487",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a0c309-6c73-48f9-917b-493922e6abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import gc\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import os\n",
    "import random \n",
    "import signal\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import threading\n",
    "import time\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e76ecc4-9fdd-44fe-873f-966ace3520ef",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9199ee1a-fa03-407b-a32b-cb35a00fada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sample_rate = 22050\n",
    "sliding_window_step = 5\n",
    "pre_process_chunk_duration_seconds = 10\n",
    "epochs = 6000\n",
    "\n",
    "random_speed_multiplier = 0.1\n",
    "\n",
    "stft_fft_length = 1024\n",
    "stft_fft_unique_bins = stft_fft_length // 2 + 1\n",
    "stft_window = 512\n",
    "stft_step = int(stft_window / 4)\n",
    "\n",
    "multithreaded_prep_train_batch_size = 40\n",
    "multithreaded_prep_test_batch_size = 15\n",
    "multithreaded_prep_chunk_size = 5\n",
    "\n",
    "model_path = \"./model\"\n",
    "losses_path = \"./model/losses\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2f7266-8c6e-4197-9fa2-02888341fd76",
   "metadata": {},
   "source": [
    "Data set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e0482-a1b1-40e6-b494-aaa82438d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://sigsep.github.io/datasets/musdb.html#musdb18-compressed-stems\n",
    "if __name__ == \"__main__\":\n",
    "    import musdb\n",
    "    db_train = musdb.DB(root=\"./musdb18\", subsets=\"train\")\n",
    "    db_test = musdb.DB(root=\"./musdb18\", subsets=\"test\")\n",
    "\n",
    "db_sample_rate = 44100\n",
    "\n",
    "# https://stackoverflow.com/questions/62558696/how-do-i-re-batch-a-tensor-in-tensorflow\n",
    "@tf.function(reduce_retracing=True)\n",
    "def sliding_window(x, axis=0):\n",
    "    window_size = sliding_window_step\n",
    "    stride = sliding_window_step\n",
    "    n_in = tf.shape(x)[axis]\n",
    "    n_out = (n_in - window_size) // stride + 1\n",
    "    # Just in case n_in < window_size\n",
    "    n_out = tf.math.maximum(n_out, 0)\n",
    "    r = tf.expand_dims(tf.range(n_out), 1)\n",
    "    idx = r * stride + tf.range(window_size)\n",
    "    return tf.gather(x, idx, axis=axis)\n",
    "\n",
    "@tf.function(reduce_retracing=True)\n",
    "def downsample(audio, source_sample_rate=db_sample_rate):\n",
    "    return tfio.audio.resample(\n",
    "        audio, \n",
    "        source_sample_rate,\n",
    "        model_sample_rate\n",
    "    )\n",
    "\n",
    "@tf.function(reduce_retracing=True)\n",
    "def separate_imaginary(stft, return_angle=False):\n",
    "    abs = tf.math.abs(stft)\n",
    "    if return_angle:\n",
    "        return abs, tf.math.angle(stft)\n",
    "    else:\n",
    "        return abs, abs\n",
    "\n",
    "def pre_process(audio, return_angle=False, source_sample_rate=db_sample_rate, is_audio_mono=False):\n",
    "    audio = audio if is_audio_mono else audio[0,:]\n",
    "    abs, angle = separate_imaginary(\n",
    "        get_stft(\n",
    "            downsample(\n",
    "                tf.convert_to_tensor(audio, dtype=tf.float32), \n",
    "                source_sample_rate=tf.convert_to_tensor(source_sample_rate, dtype=tf.int64)\n",
    "            )\n",
    "        ), \n",
    "        return_angle=return_angle\n",
    "    )\n",
    "\n",
    "    if return_angle:\n",
    "        return sliding_window(abs), sliding_window(angle)\n",
    "    else:\n",
    "        return sliding_window(abs)\n",
    "\n",
    "def pre_process_track(track):\n",
    "    track.chunk_duration = pre_process_chunk_duration_seconds\n",
    "    track.chunk_start = random.uniform(0, track.duration - track.chunk_duration)\n",
    "    sample_rate = int(\n",
    "        db_sample_rate * random.uniform(\n",
    "            1 - random_speed_multiplier, \n",
    "            1 + random_speed_multiplier\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    x = pre_process(\n",
    "        track.targets['linear_mixture'].audio.T,\n",
    "        source_sample_rate=sample_rate\n",
    "    )\n",
    "    y = [\n",
    "        pre_process(track.targets['drums'].audio.T, source_sample_rate=sample_rate),\n",
    "        pre_process(track.targets['bass'].audio.T, source_sample_rate=sample_rate),\n",
    "        pre_process(track.targets['other'].audio.T, source_sample_rate=sample_rate),\n",
    "        pre_process(track.targets['vocals'].audio.T, source_sample_rate=sample_rate)\n",
    "    ]\n",
    "\n",
    "    return x, y\n",
    "\n",
    "@tf.function\n",
    "def post_process(magnitudes, angles):\n",
    "    return tf.reshape(\n",
    "        tf.complex(\n",
    "            tf.math.multiply(magnitudes, tf.math.cos(angles)),\n",
    "            tf.math.multiply(magnitudes, tf.math.sin(angles))\n",
    "        ), \n",
    "        [-1, stft_fft_unique_bins]\n",
    "    )\n",
    "\n",
    "def post_process_track(stfts, angles):\n",
    "    stfts = list(map(\n",
    "        lambda x: post_process(x, angles),\n",
    "        stfts\n",
    "    ))\n",
    "    return stfts, list(map(\n",
    "        lambda x: get_inverse_stft(x),\n",
    "        stfts\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2f51e8-1fa4-4828-89ae-5112f53f1430",
   "metadata": {},
   "source": [
    "STFT set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75bd661-058c-48bd-8bbb-904ceb6a07e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(reduce_retracing=True)\n",
    "def get_stft(audio):\n",
    "    return tf.signal.stft(\n",
    "        audio,\n",
    "        stft_window,\n",
    "        stft_step,\n",
    "        fft_length=stft_fft_length\n",
    "    )\n",
    "\n",
    "def get_inverse_stft(stft):\n",
    "    return tf.signal.inverse_stft(\n",
    "        stft,\n",
    "        stft_window,\n",
    "        stft_step,\n",
    "        fft_length=stft_fft_length\n",
    "    ).numpy()\n",
    "\n",
    "def display_stfts(stfts, names=[\"Drums\", \"Bass\", \"Other\", \"Vocals\"]):\n",
    "    fig = plt.figure(figsize=(16,4))\n",
    "    for i, stft in enumerate(stfts):\n",
    "        fig.add_subplot(1, 4, i + 1)\n",
    "        plt.imshow(\n",
    "            numpy.transpose(tf.math.log(1 + tf.abs(stft)).numpy()), \n",
    "            aspect='auto', \n",
    "            origin='lower'\n",
    "        )\n",
    "        plt.title(names[i])\n",
    "        plt.xlabel('Time frame')\n",
    "        plt.ylabel('Frequency bin')\n",
    "    plt.show()\n",
    "\n",
    "def display_audio(audio, max_seconds = 60, sr = model_sample_rate):\n",
    "    IPython.display.display(\n",
    "        IPython.display.Audio(\n",
    "            numpy.transpose(audio)[:sr * max_seconds], \n",
    "            rate=sr\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a913a6e1-76a8-4e66-9148-d6c899f483e1",
   "metadata": {},
   "source": [
    "Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0152c090-0093-45d0-8166-23bade9448c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.saving.register_keras_serializable()\n",
    "class Mask(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        layer_input, model_input, all_dense = inputs\n",
    "        return tf.math.multiply(\n",
    "            tf.math.divide(\n",
    "                layer_input, \n",
    "                tf.math.add_n(all_dense)\n",
    "            ), \n",
    "            model_input\n",
    "        )\n",
    "\n",
    "def create_model():\n",
    "    input = tf.keras.layers.Input(shape=(sliding_window_step, stft_fft_unique_bins), name=\"input_stft\")\n",
    "    \n",
    "    lstm = tf.keras.layers.LSTM(stft_fft_unique_bins * 2, return_sequences=True, name=\"1st_lstm\")(input)\n",
    "    lstm = tf.keras.layers.LSTM(stft_fft_unique_bins * 2, return_sequences=True, name=\"2nd_lstm\")(lstm)\n",
    "    lstm = tf.keras.layers.LSTM(stft_fft_unique_bins * 2, return_sequences=True, name=\"3rd_lstm\")(lstm)\n",
    "    \n",
    "    dense_drums = tf.keras.layers.Dense(stft_fft_unique_bins, name=\"drums_dense\")(lstm)\n",
    "    dense_bass = tf.keras.layers.Dense(stft_fft_unique_bins, name=\"bass_dense\")(lstm)\n",
    "    dense_other = tf.keras.layers.Dense(stft_fft_unique_bins, name=\"other_dense\")(lstm)\n",
    "    dense_vocals = tf.keras.layers.Dense(stft_fft_unique_bins, name=\"vocals_dense\")(lstm)\n",
    "    \n",
    "    output_drums = Mask(name=\"drums_output\")((dense_drums, input, [dense_drums, dense_bass, dense_other, dense_vocals]))\n",
    "    output_bass = Mask(name=\"bass_output\")((dense_bass, input, [dense_drums, dense_bass, dense_other, dense_vocals]))\n",
    "    output_other = Mask(name=\"other_output\")((dense_other, input, [dense_drums, dense_bass, dense_other, dense_vocals]))\n",
    "    output_vocals = Mask(name=\"vocals_output\")((dense_vocals, input, [dense_drums, dense_bass, dense_other, dense_vocals]))\n",
    "    \n",
    "    return tf.keras.Model(input, [output_drums, output_bass, output_other, output_vocals])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = create_model()\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    starting_weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d466d2af-c859-4d43-8f59-e177c1d33edf",
   "metadata": {},
   "source": [
    "Multithreading set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e859919-6c16-48ae-8f4c-960aed10093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://alexandra-zaharia.github.io/posts/how-to-return-a-result-from-a-python-thread/\n",
    "class ReturnValueThread(threading.Thread):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.result = None\n",
    "\n",
    "    def run(self):\n",
    "        if self._target is None:\n",
    "            return\n",
    "        self.result = self._target(*self._args, **self._kwargs)\n",
    "\n",
    "    def join(self, *args, **kwargs):\n",
    "        super().join(*args, **kwargs)\n",
    "        return self.result\n",
    "\n",
    "def pre_process_batch(batch):\n",
    "    result = []\n",
    "    for track in batch:\n",
    "        result.append(pre_process_track(track))\n",
    "    return result\n",
    "        \n",
    "def start_prep_multithreaded():\n",
    "    gc.collect()\n",
    "\n",
    "    db_train_subset = random.sample(db_train.tracks, k=multithreaded_prep_train_batch_size)\n",
    "    db_test_subset = random.sample(db_test.tracks, k=multithreaded_prep_test_batch_size)\n",
    "    \n",
    "    train_chunks = [db_train_subset[x:x+multithreaded_prep_chunk_size] for x in range(0, len(db_train_subset), multithreaded_prep_chunk_size)]\n",
    "    test_chunks = [db_test_subset[x:x+multithreaded_prep_chunk_size] for x in range(0, len(db_test_subset), multithreaded_prep_chunk_size)]\n",
    "\n",
    "    train_threads = []\n",
    "    test_threads = []\n",
    "    \n",
    "    train_batch = []\n",
    "    test_batch = []\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for chunk in train_chunks:\n",
    "        thread = ReturnValueThread(\n",
    "            target=pre_process_batch, \n",
    "            args=(chunk,)\n",
    "        )\n",
    "        thread.start()\n",
    "        train_threads.append(thread)\n",
    "\n",
    "    for chunk in test_chunks:\n",
    "        thread = ReturnValueThread(\n",
    "            target=pre_process_batch, \n",
    "            args=(chunk,)\n",
    "        )\n",
    "        thread.start()\n",
    "        test_threads.append(thread)\n",
    "\n",
    "    def join_threads():\n",
    "        joined_count = 0\n",
    "        thread_count = len(train_threads) + len(test_threads)\n",
    "        print(f\"\\r{joined_count} out of {thread_count} threads finished\", end = \"\")\n",
    "        while len(train_threads) > 0 or len(test_threads) > 0:\n",
    "            for i, thread in enumerate(train_threads):\n",
    "                result = thread.join(0.01)\n",
    "                if result:\n",
    "                    joined_count += 1\n",
    "                    print(f\"\\r{joined_count} out of {thread_count} threads finished\", end = \"\")\n",
    "                    train_batch.extend(result)\n",
    "                    train_threads.remove(thread)\n",
    "    \n",
    "            for i, thread in enumerate(test_threads):\n",
    "                result = thread.join(0.01)\n",
    "                if result:\n",
    "                    joined_count += 1\n",
    "                    print(f\"\\r{joined_count} out of {thread_count} threads finished\", end = \"\")\n",
    "                    test_batch.extend(result)\n",
    "                    test_threads.remove(thread)\n",
    "        print(\"\")\n",
    "        return train_batch, test_batch\n",
    "\n",
    "    return join_threads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e164a0-f713-4d32-8916-5eba574479ab",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01c40a4-9da9-42f8-b5d8-139d83869d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses\n",
    "if __name__ == \"__main__\":\n",
    "    loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "    train_acc_metric = tf.keras.metrics.MeanSquaredError()\n",
    "    test_acc_metric = tf.keras.metrics.MeanSquaredError()\n",
    "\n",
    "def read_losses(file_name):\n",
    "    arr = []\n",
    "    with open(f\"{losses_path}/{file_name}.csv\", \"r\") as losses_file:\n",
    "        for line in losses_file:\n",
    "            vals = line.split(\",\")\n",
    "            arr.append([float(vals[0]), float(vals[1])])\n",
    "    arr = numpy.transpose(arr)\n",
    "    return arr[0].tolist(), arr[1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6d9b65-117d-4c8b-b3ea-802f33e9436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset training\n",
    "if __name__ == \"__main__\":\n",
    "    epoch = 1\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    model.set_weights(starting_weights)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=0.001,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999\n",
    "    )\n",
    "    \n",
    "    checkpoint = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "    \n",
    "    restore_name = None\n",
    "    # restore_name = ''\n",
    "    \n",
    "    if restore_name:\n",
    "        checkpoint.restore(f'{model_path}/{restore_name}')\n",
    "        epoch = int(restore_name.split('_')[1]) + 1\n",
    "        train_losses, test_losses = read_losses(restore_name)\n",
    "\n",
    "def print_model_predict(track_index = None, track_start = None): \n",
    "    display_track = db_test[track_index] if track_index is not None else random.choice(db_test)\n",
    "    display_track.chunk_duration = pre_process_chunk_duration_seconds\n",
    "    display_track.chunk_start = track_start or random.uniform(0, display_track.duration - display_track.chunk_duration)\n",
    "    \n",
    "    input, angle = pre_process(display_track.audio.T, return_angle=True)\n",
    "    stft_input = post_process(input, angle)\n",
    "    results = model.predict(input)\n",
    "    \n",
    "    stft_drums = post_process(results[0], angle)\n",
    "    stft_bass = post_process(results[1], angle)\n",
    "    stft_other = post_process(results[2], angle)\n",
    "    stft_vocals = post_process(results[3], angle)\n",
    "    \n",
    "    display_stfts([stft_drums, stft_bass, stft_other, stft_vocals])\n",
    "    print(\"Original: \")\n",
    "    display_audio(get_inverse_stft(stft_input))\n",
    "    print(\"Drums: \")\n",
    "    display_audio(get_inverse_stft(stft_drums))\n",
    "    print(\"Bass: \")\n",
    "    display_audio(get_inverse_stft(stft_bass))\n",
    "    print(\"Other: \")\n",
    "    display_audio(get_inverse_stft(stft_other))\n",
    "    print(\"Vocals: \")\n",
    "    display_audio(get_inverse_stft(stft_vocals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed18dedd-14cc-4b59-aa9d-ea201051282d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afee25d-89ce-4d3a-9a90-c3b2cf1699da",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(reduce_retracing=True)\n",
    "def train_step(x, y):\n",
    "    y = tf.convert_to_tensor(y)\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x, training=True)\n",
    "        logits = tf.convert_to_tensor(logits)\n",
    "        loss_value = loss_fn(y, logits)\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    train_acc_metric.update_state(y, logits)\n",
    "    return loss_value\n",
    "\n",
    "@tf.function(reduce_retracing=True)\n",
    "def test_step(x, y):\n",
    "    logits = model(x, training=False)\n",
    "    test_acc_metric.update_state(y, logits)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gc.collect()\n",
    "    \n",
    "    join_threads = start_prep_multithreaded()\n",
    "    \n",
    "    while epoch <= epochs:\n",
    "        print(f\"\\nStart of epoch {epoch}\")\n",
    "        start = time.time()\n",
    "    \n",
    "        train_batch, test_batch = join_threads()\n",
    "        join_threads = start_prep_multithreaded()\n",
    "        random.shuffle(train_batch)\n",
    "        \n",
    "        for step, track in enumerate(train_batch):\n",
    "            \n",
    "            train_x, train_y = track\n",
    "            loss_value = train_step(train_x, train_y)\n",
    "            \n",
    "            print(f\"\\rTraining step {step + 1}. Loss: {float(loss_value):.4f} Time taken (seconds): {float(time.time()-start):.2f}\", end=\"\")\n",
    "    \n",
    "            if tf.math.is_nan(loss_value): \n",
    "                raise ValueError(f'loss_value became NaN during epoch {epoch}, step {step + 1} at {datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}')\n",
    "        \n",
    "        train_acc = train_acc_metric.result()\n",
    "        train_losses.append(train_acc)\n",
    "        print(\"\\nTraining loss over epoch: %.4f\" % (train_losses[-1],), end=\"\")\n",
    "        train_acc_metric.reset_states()\n",
    "    \n",
    "        for step, track in enumerate(test_batch):\n",
    "            test_x, test_y = track\n",
    "            test_step(test_x, test_y)\n",
    "    \n",
    "        test_acc = test_acc_metric.result()\n",
    "        test_losses.append(test_acc)\n",
    "        print(\"\\tTest loss: %.4f\" % (float(test_acc),))    \n",
    "        test_acc_metric.reset_states()\n",
    "    \n",
    "        if epoch % 40 == 0:\n",
    "            new_filename = f'epoch_{epoch}_with_{optimizer.name}-{optimizer.learning_rate.numpy():.3f}_at_{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}'\n",
    "            checkpoint.save(f\"{model_path}/{new_filename}\")\n",
    "            with open(f\"{losses_path}/{new_filename}-{checkpoint.save_counter.numpy()}.csv\", \"w\") as losses_file:\n",
    "                for line in numpy.transpose([train_losses, test_losses]):\n",
    "                    losses_file.write(f\"{line[0]},{line[1]}\\n\")\n",
    "        \n",
    "        if epoch % 20 == 0:\n",
    "            print_model_predict()\n",
    "        \n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77e89f0-938f-4ea1-9ae5-84336905f51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model.save('./model_6000.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17b3bf0-c881-4307-b3b4-565a8ae2996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for i in range(4):\n",
    "        print_model_predict(track_index = i, track_start = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f34511-68aa-4d9b-884c-0656f225fca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
